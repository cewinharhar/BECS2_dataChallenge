{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary packages\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import numpy as np\n",
    "\n",
    "import xgboost\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#to save model\n",
    "import joblib\n",
    "\n",
    "\"\"\"\n",
    "usage joblib\n",
    "# save the model: \n",
    "joblib.dump(model , \"model.pkl\")\n",
    "# load the model:\n",
    "model = joblib.load(\"model.pkl\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We want to have a dataframe with:\n",
    "* X: rows = patients, cols = proteins filled with the protein quantity\n",
    "* y: rows = patients, col  = health condition (healthy, cancer A, cancer B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"rawData/tidy.csv\"\n",
    "pathMet = \"rawData/metadata.csv\"\n",
    "tidy = pd.read_csv(path, sep=\",\")\n",
    "tidyMet = pd.read_csv(pathMet, sep=\";\", index_col=0)\n",
    "\n",
    "#remove all samples which are not in the metadata index column (quality controle etc)\n",
    "tidy = tidy[ (tidy[\"R.FileName\"].isin(tidyMet.index)) ]\n",
    "\n",
    "tidyMer    = pd.merge(tidy, tidyMet, how=\"left\", on=\"R.FileName\")\n",
    "\n",
    "tidySub = tidyMer[[\"R.FileName\", \"uniprot\", \"meanAbu\", \"Cancer\"]]\n",
    "\n",
    "tidySub.Cancer.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To feed the data inot a model we need to reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape data\n",
    "#X data\n",
    "tidyReshaped = tidySub.pivot(index = \"R.FileName\", columns = \"uniprot\", values = \"meanAbu\")\n",
    "tidyReshaped.head()\n",
    "#y condition\n",
    "Group =  tidySub.drop([\"uniprot\", \"meanAbu\"], axis=1)\n",
    "Group = Group.drop_duplicates().reset_index(drop=True)\n",
    "Group.head()\n",
    "\n",
    "#we merge to ensure that the y rows fit the corresponding x rows\n",
    "data = pd.merge(tidyReshaped, Group, how=\"left\", on=\"R.FileName\")\n",
    "\n",
    "#to make df purely numerical\n",
    "data = data.set_index(\"R.FileName\")\n",
    "\n",
    "X = data.iloc[:, :-1]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that the data is prepared we continue with the following steps:\n",
    "* Create pipeline for imputing, scaling !! **Scaling is not needed for Random Forest**\n",
    "* (https://towardsdatascience.com/how-data-normalization-affects-your-random-forest-algorithm-fbc6753b4ddf)\n",
    "* Creation of training, validation and test sets\n",
    "* Feature Selection, Engineering\n",
    "* Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "dataPrepPipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ]) \n",
    "\n",
    "#X is already purely numerical\n",
    "X = dataPrepPipe.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target labels\n",
    "from sklearn import preprocessing\n",
    "\n",
    "labEnc = preprocessing.LabelEncoder() \n",
    "\n",
    "# apply label encoding\n",
    "y = labEnc.fit_transform(y) \n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save X and y for next session\n",
    "\n",
    "joblib.dump(y, \"Models/y.pkl\")\n",
    "joblib.dump(X, \"Models/X.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load saved X and y \n",
    "\n",
    "y = joblib.load(\"Models/y.pkl\")\n",
    "X = joblib.load(\"Models/X.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "\n",
    "\"\"\"\n",
    "Can be used in pipeline\n",
    "clf = Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\"))),\n",
    "  ('classification', RandomForestClassifier())\n",
    "])\n",
    "\"\"\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel #checkout description https://scikit-learn.org/stable/modules/feature_selection.html#tree-based-feature-selection\n",
    "\n",
    "#create Random Forest classifier with default hyperparameters\n",
    "raFo = RandomForestClassifier()\n",
    "raFo = raFo.fit(X, y)\n",
    "\n",
    "#checkout importance in a histogram\n",
    "plt.hist(raFo.feature_importances_, bins=100)\n",
    "\n",
    "#get the reduced X\n",
    "model = SelectFromModel(estimator = raFo, prefit=True)\n",
    "X_new = model.transform(X)\n",
    "\n",
    "print(f\"Original X shape: {X.shape}\")\n",
    "print(f\"Feature selected X_new shape: {X_new.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "\n",
    "importances = raFo.feature_importances_\n",
    "\n",
    "std = np.std([tree.feature_importances_ for tree in raFo.estimators_], axis=0)\n",
    "std.sort()\n",
    "\n",
    "forest_importances = pd.Series(importances)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")\n",
    "ax.get_xaxis().set_visible(False)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\"\"\" plt.rcParams[\"figure.figsize\"] = (10,5)\n",
    "plt.bar(raFo.feature_names, raFo.feature_importances_)\n",
    "plt.xlabel('Feature Labels')\n",
    "plt.ylabel('Feature Importances')\n",
    "plt.title('Comparison of different Feature Importances'); \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import already trained model\n",
    "\n",
    "clf_RF = joblib.load(\"Models/clf_RF_X_new.pkl\")\n",
    "clf_XGRF = joblib.load(\"Models/clf_XGRF_X_new.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_new, y, test_size=0.2, random_state=3)\n",
    "\n",
    "clf_RF = RandomForestClassifier(random_state=1)\n",
    "clf_RF.fit(X_train ,y_train)\n",
    "y_RFpred = clf_RF.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "print(\"Accuracy Random Forest:\",metrics.accuracy_score(y_test , y_RFpred))\n",
    "print(classification_report(y_test, y_RFpred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some parameters for xgboost to avoid warnings\n",
    "params = dict(tree_method=\"exact\", \n",
    "                eval_metric='mlogloss',\n",
    "                use_label_encoder =False)\n",
    "\n",
    "clf_XGRF = xgboost.XGBClassifier(random_state=4, **params)\n",
    "\n",
    "clf_XGRF.fit(X_train ,y_train)\n",
    "y_XGRFpred = clf_XGRF.predict(X_test)\n",
    "\n",
    "print(\"Accuracy XGBoost Random Forest:\",metrics.accuracy_score(y_test , y_XGRFpred))\n",
    "print(classification_report(y_test, y_XGRFpred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "joblib.dump(clf_RF, \"Models/clf_RF_X_new.pkl\")\n",
    "joblib.dump(clf_XGRF, \"Models/clf_XGRF_X_new.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, y_RFpred, labels=clf_RF.classes_) # calculate value\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,              # display\n",
    "                              display_labels=clf_RF.classes_)\n",
    "disp.plot(); \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare uncertainty of Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_RF, X_new, y, cv=5, scoring='accuracy')\n",
    "Udata = scores.std()\n",
    "\n",
    "modAcuRF = []\n",
    "for rs in range(1,6):\n",
    "    model = RandomForestClassifier(random_state=random.randrange(rs))\n",
    "    model.fit(X_train, y_train)\n",
    "    modAcuRF += [accuracy_score(y_test, model.predict(X_test))]\n",
    "\n",
    "Umodel = np.std(modAcuRF)\n",
    "\n",
    "print(\"Uncertainty in the data: %.3f\" % Udata)\n",
    "print(\"Uncertainty in the model: %.3f\" % Umodel)\n",
    "print(\"The model performance is %.3f ± %.3f ± %.3f\" % (scores.mean(),Udata,Umodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(clf_XGRF, X_new, y, cv=5, scoring='accuracy')\n",
    "Udata = scores.std()\n",
    "\n",
    "\n",
    "modAcuXGRF = []\n",
    "for rs in range(1,6):\n",
    "    model = xgboost.XGBClassifier(random_state=random.randrange(rs), **params)\n",
    "    model.fit(X_train, y_train)\n",
    "    modAcuXGRF += [accuracy_score(y_test, model.predict(X_test))]\n",
    "\n",
    "Umodel = np.std(modAcuXGRF)\n",
    "\n",
    "print(\"Uncertainty in the data: %.3f\" % Udata)\n",
    "print(\"Uncertainty in the model: %.3f\" % Umodel)\n",
    "print(\"The model performance is %.3f ± %.3f ± %.3f\" % (scores.mean(),Udata,Umodel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43fef3abedee1d893beac1d2d118646f520aa845e2b69655f65decb73f4f0136"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('python38_r411': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
